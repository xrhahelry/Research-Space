@inproceedings{10.1145/2939672.2939673,
author = {Zhang, Fuzheng and Yuan, Nicholas Jing and Lian, Defu and Xie, Xing and Ma, Wei-Ying},
title = {Collaborative Knowledge Base Embedding for Recommender Systems},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939673},
doi = {10.1145/2939672.2939673},
abstract = {Among different recommendation techniques, collaborative filtering usually suffer from limited performance due to the sparsity of user-item interactions. To address the issues, auxiliary information is usually used to boost the performance. Due to the rapid collection of information on the web, the knowledge base provides heterogeneous information including both structured and unstructured data with different semantics, which can be consumed by various applications. In this paper, we investigate how to leverage the heterogeneous information in a knowledge base to improve the quality of recommender systems. First, by exploiting the knowledge base, we design three components to extract items' semantic representations from structural content, textual content and visual content, respectively. To be specific, we adopt a heterogeneous network embedding method, termed as TransR, to extract items' structural representations by considering the heterogeneity of both nodes and relationships. We apply stacked denoising auto-encoders and stacked convolutional auto-encoders, which are two types of deep learning based embedding techniques, to extract items' textual representations and visual representations, respectively. Finally, we propose our final integrated framework, which is termed as Collaborative Knowledge Base Embedding (CKE), to jointly learn the latent representations in collaborative filtering as well as items' semantic representations from the knowledge base. To evaluate the performance of each embedding component as well as the whole system, we conduct extensive experiments with two real-world datasets from different scenarios. The results reveal that our approaches outperform several widely adopted state-of-the-art recommendation methods.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {353–362},
numpages = {10},
keywords = {recommender systems, knowledge base embedding, collaborative joint learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@misc{liu2025academicliteraturerecommendationlargescale,
      title={Academic Literature Recommendation in Large-scale Citation Networks Enhanced by Large Language Models},
      author={Kun Liu and Yan Zhang and Rui Pan and Tianchen Gao and Hansheng Wang},
      year={2025},
      eprint={2503.01189},
      archivePrefix={arXiv},
      primaryClass={stat.AP},
      url={https://arxiv.org/abs/2503.01189},
}

@misc{church2024academicarticlerecommendationusing,
      title={Academic Article Recommendation Using Multiple Perspectives},
      author={Kenneth Church and Omar Alonso and Peter Vickers and Jiameng Sun and Abteen Ebrahimi and Raman Chandrasekar},
      year={2024},
      eprint={2407.05836},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2407.05836},
}

@misc{beltagy2019scibertpretrainedlanguagemodel,
      title={SciBERT: A Pretrained Language Model for Scientific Text},
      author={Iz Beltagy and Kyle Lo and Arman Cohan},
      year={2019},
      eprint={1903.10676},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1903.10676},
}

@inproceedings{NIPS2013_1cecc7a7,
 author = {Bordes, Antoine and Usunier, Nicolas and Garcia-Duran, Alberto and Weston, Jason and Yakhnenko, Oksana},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Translating Embeddings for Modeling Multi-relational Data},
 url = {https://proceedings.neurips.cc/paper_files/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf},
 volume = {26},
 year = {2013}
}

@misc{wang2021graphlearningbasedrecommender,
      title={Graph Learning based Recommender Systems: A Review},
      author={Shoujin Wang and Liang Hu and Yan Wang and Xiangnan He and Quan Z. Sheng and Mehmet A. Orgun and Longbing Cao and Francesco Ricci and Philip S. Yu},
      year={2021},
      eprint={2105.06339},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2105.06339},
}

@inproceedings{10.1145/3292500.3330673,
    author = {Fan, Shaohua and Zhu, Junxiong and Han, Xiaotian and Shi, Chuan and Hu, Linmei and Ma, Biyu and Li, Yongliang},
    title = {Metapath-guided Heterogeneous Graph Neural Network for Intent Recommendation},
    year = {2019},
    isbn = {9781450362016},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3292500.3330673},
    doi = {10.1145/3292500.3330673},
    abstract = {With the prevalence of mobile e-commerce nowadays, a new type of recommendation services, called intent recommendation, is widely used in many mobile e-commerce Apps, such as Taobao and Amazon. Different from traditional query recommendation and item recommendation, intent recommendation is to automatically recommend user intent according to user historical behaviors without any input when users open the App. Intent recommendation becomes very popular in the past two years, because of revealing user latent intents and avoiding tedious input in mobile phones. Existing methods used in industry usually need laboring feature engineering. Moreover, they only utilize attribute and statistic information of users and queries, and fail to take full advantage of rich interaction information in intent recommendation, which may result in limited performances. In this paper, we propose to model the complex objects and rich interactions in intent recommendation as a Heterogeneous Information Network. Furthermore, we present a novel M etapath-guided E mbedding method for I ntent Rec ommendation~(called MEIRec). In order to fully utilize rich structural information, we design a metapath-guided heterogeneous Graph Neural Network to learn the embeddings of objects in intent recommendation. In addition, in order to alleviate huge learning parameters in embeddings, we propose a uniform term embedding mechanism, in which embeddings of objects are made up with the same term embedding space. Offline experiments on real large-scale data show the superior performance of the proposed MEIRec, compared to representative methods.Moreover, the results of online experiments on Taobao e-commerce platform show that MEIRec not only gains a performance improvement of 1.54\% on CTR metric, but also attracts up to 2.66\% of new users to search queries.},
    booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
    pages = {2478–2486},
    numpages = {9},
    keywords = {graph neural network, heterogeneous information network, intent recommendation, recommender systems},
    location = {Anchorage, AK, USA},
    series = {KDD '19}
}

@inproceedings{10.1145/3109859.3109889,
    author = {Palumbo, Enrico and Rizzo, Giuseppe and Troncy, Rapha\"{e}l},
    title = {entity2rec: Learning User-Item Relatedness from Knowledge Graphs for Top-N Item Recommendation},
    year = {2017},
    isbn = {9781450346528},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3109859.3109889},
    doi = {10.1145/3109859.3109889},
    abstract = {Knowledge Graphs have proven to be extremely valuable to recommender systems, as they enable hybrid graph-based recommendation models encompassing both collaborative and content information. Leveraging this wealth of heterogeneous information for top-N item recommendation is a challenging task, as it requires the ability of effectively encoding a diversity of semantic relations and connectivity patterns. In this work, we propose entity2rec, a novel approach to learning user-item relatedness from knowledge graphs for top-N item recommendation. We start from a knowledge graph modeling user-item and item-item relations and we learn property-specific vector representations of users and items applying neural language models on the network. These representations are used to create property-specific user-item relatedness features, which are in turn fed into learning to rank algorithms to learn a global relatedness model that optimizes top-N item recommendations. We evaluate the proposed approach in terms of ranking quality on the MovieLens 1M dataset, outperforming a number of state-of-the-art recommender systems, and we assess the importance of property-specific relatedness scores on the overall ranking quality.},
    booktitle = {Proceedings of the Eleventh ACM Conference on Recommender Systems},
    pages = {32–36},
    numpages = {5},
    keywords = {hybrid recommender system, knowledge graph, knowledge graph embeddings, learning to rank, linked open data, neural language models, node2vec, word2vec},
    location = {Como, Italy},
    series = {RecSys '17}
}

@article{10.3233/JIFS-202177,
author = {Zhang, Zhenghang and Jia, Jinlu and Wan, Yalin and Zhou, Yang and Kong, Yuting and Qian, Yurong and Long, Jun},
title = {TransR*: Representation learning model by flexible translation and relation matrix projection},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {40},
number = {5},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-202177},
doi = {10.3233/JIFS-202177},
abstract = {The TransR model solves the problem that TransE and TransH models are not sufficient for modeling in public spaces, and is considered a highly potential knowledge representation model. However, TransR still adopts the translation principles based on the TransE model, and the constraints are too strict, which makes the model’s ability to distinguish between very similar entities low. Therefore, we propose a representation learning model TransR* based on flexible translation and relational matrix projection. Firstly, we separate entities and relationships in different vector spaces; secondly, we combine our flexible translation strategy to make translation strategies more flexible. During model training, the quality of generating negative triples is improved by replacing semantically similar entities, and the prior probability of the relationship is used to distinguish the relationship of similar coding. Finally, we conducted link prediction experiments on the public data sets FB15K and WN18, and conducted triple classification experiments on the WN11, FB13, and FB15K data sets to analyze and verify the effectiveness of the proposed model. The evaluation results show that our method has a better improvement effect than TransR on Mean Rank, Hits@10 and ACC indicators.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {10251–10259},
numpages = {9},
keywords = {triple classification, link prediction, relation matrix projection, flexible translation, Knowledge representation}
}

@misc{song2022ekarexplainablemethodknowledge,
    title={Ekar: An Explainable Method for Knowledge Aware Recommendation},
    author={Weiping Song and Zhijian Duan and Ziqing Yang and Hao Zhu and Ming Zhang and Jian Tang},
    year={2022},
    eprint={1906.09506},
    archivePrefix={arXiv},
    primaryClass={cs.IR},
    url={https://arxiv.org/abs/1906.09506},
}

@misc{edge2025localglobalgraphrag,
      title={From Local to Global: A Graph RAG Approach to Query-Focused Summarization},
      author={Darren Edge and Ha Trinh and Newman Cheng and Joshua Bradley and Alex Chao and Apurva Mody and Steven Truitt and Dasha Metropolitansky and Robert Osazuwa Ness and Jonathan Larson},
      year={2025},
      eprint={2404.16130},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.16130},
}

@inproceedings{zhang2019prone,
  title={Prone: Fast and scalable network representation learning.},
  author={Zhang, Jie and Dong, Yuxiao and Wang, Yan and Tang, Jie and Ding, Ming},
  booktitle={IJCAI},
  volume={19},
  pages={4278--4284},
  year={2019}
}

@inproceedings{cohan-etal-2020-specter,
    title = "{SPECTER}: Document-level Representation Learning using Citation-informed Transformers",
    author = "Cohan, Arman  and
      Feldman, Sergey  and
      Beltagy, Iz  and
      Downey, Doug  and
      Weld, Daniel",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.207/",
    doi = "10.18653/v1/2020.acl-main.207",
    pages = "2270--2282",
    abstract = "Representation learning is a critical ingredient for natural language processing systems. Recent Transformer language models like BERT learn powerful textual representations, but these models are targeted towards token- and sentence-level training objectives and do not leverage information on inter-document relatedness, which limits their document-level representation power. For applications on scientific documents, such as classification and recommendation, accurate embeddings of documents are a necessity. We propose SPECTER, a new method to generate document-level embedding of scientific papers based on pretraining a Transformer language model on a powerful signal of document-level relatedness: the citation graph. Unlike existing pretrained language models, Specter can be easily applied to downstream applications without task-specific fine-tuning. Additionally, to encourage further research on document-level models, we introduce SciDocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation. We show that Specter outperforms a variety of competitive baselines on the benchmark."
}

@INPROCEEDINGS{10295108,
  author={Issa, Bayan and Jasser, Muhammed Basheer and Chua, Hui Na and Hamzah, Muzaffar},
  booktitle={2023 IEEE 13th International Conference on System Engineering and Technology (ICSET)},
  title={A Comparative Study on Embedding Models for Keyword Extraction Using KeyBERT Method},
  year={2023},
  volume={},
  number={},
  pages={40-45},
  keywords={Analytical models;Technological innovation;Sentiment analysis;Computational modeling;Text categorization;Transformers;Libraries;Keyword Extraction;NLP;Pretrained Model;Embedding Models},
  doi={10.1109/ICSET59111.2023.10295108}
}
